# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DIGwjexKkRX3aN65GPPP_dixZeVtCOAw
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/gdrive')

import zipfile

dataset_path="/content/gdrive/My Drive/archive.zip"
zfile=zipfile.ZipFile(dataset_path)
zfile.extractall()

import os
import numpy as np
import pandas as pd
import tensorflow
import matplotlib.pyplot as plt
import tensorflow as tf

import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D
from sklearn.datasets import load_files
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization

train_path = '/content/tiny-imagenet-200/train'        
test_path = '/content/tiny-imagenet-200/test' 
val_path = '/content/tiny-imagenet-200/val'

import cv2

from PIL import Image

im = Image.open("../content/tiny-imagenet-200/train/n01443537/images/n01443537_209.JPEG")
tlabel = np.asarray(Image.open("../content/tiny-imagenet-200/train/n01443537/images/n01443537_209.JPEG")) // 1000
tlabel[tlabel != 0] = 255
# plt.imshow(Image.blend(im, Image.fromarray(tlabel).convert('RGB'), alpha=0.4))
plt.imshow(im)
display(plt.show())

from keras import backend as K 
print(os.listdir("../content/tiny-imagenet-200"))  
for dirname, _, filenames in os.walk('/content/tiny-imagenet-200'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

K.set_learning_phase(1)

img_width, img_height = 224, 224   
epochs = 10  
batch_size = 32  
n_classes = 200



train_data_dir = '/content/tiny-imagenet-200/train'
validation_data_dir = '/content/tiny-imagenet-200/val'


train_datagen = ImageDataGenerator(  
    rescale=1. / 255,
    zoom_range=0.2,
    rotation_range = 5,
    horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(  
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(  
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

history = model.fit_generator(train_generator, epochs=25, validation_data = validation_generator, verbose = 1)

model.save("rps.h5")